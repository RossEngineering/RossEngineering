# RossEngineering — AI Usage Policy

This document describes how artificial intelligence (AI) tools are used within the RossEngineering organisation.

It exists to support **openness, honesty, and engineering discipline**, not to restrict legitimate tooling or create performative constraints.

AI is treated as a **collaborative development tool**, not a substitute for understanding, ownership, or responsibility.

---

## Purpose

This policy exists to:

- Be open and honest about AI usage
- Set clear expectations for acceptable practice
- Reinforce that responsibility and understanding remain with the engineer
- Prevent the gradual drift into insecure, poorly understood systems

It is a statement of **how work is done**, not a moral or ethical manifesto.

---

## Position on AI

AI is used as a **collaborative partner** in development.

It is appropriate for:
- discussion
- iteration
- critique
- drafting
- refactoring
- test generation
- architectural exploration

AI is not treated as an authority.  
Final responsibility always rests with the human engineer.

---

## Understanding & Ownership

A core requirement of all work in RossEngineering is **understanding**.

- Code generated or suggested by AI is acceptable **only if it is fully understood**
- If code cannot be explained clearly, it does not ship
- Production code must be defensible on a whiteboard, without AI assistance

AI may accelerate development, but it does not transfer ownership.

---

## Code Generation

AI-assisted code generation is acceptable when:

- The code is reviewed and understood
- The behaviour is verified (tests, reasoning, or both)
- The code aligns with the project’s architecture and standards

There are no blanket exclusions (such as “no AI in core logic”), provided review and understanding requirements are met.

If AI-generated code cannot be confidently explained, it is treated as **unfinished work**.

---

## Testing

AI-generated tests are explicitly encouraged.

- Tests may be authored, expanded, or refactored with AI assistance
- Tests must still reflect real behaviour and meaningful assertions
- Poor or superficial tests are unacceptable regardless of authorship

The goal is higher confidence, not artificial coverage.

---

## Architecture & Design

AI may be used to:

- explore architectural options
- challenge assumptions
- surface trade-offs
- critique designs

Architectural decisions remain a **human responsibility**.

AI is treated as a collaborator and sounding board, not a decision-maker.  
Where disagreement exists, the engineer has final say.

---

## Documentation

AI may be used to assist with:

- README drafting
- decision logs
- ADRs
- diagrams and explanations

All documentation is reviewed, edited, and owned by the maintainer.

Clarity, accuracy, and intent matter more than authorship mechanics.

---

## Attribution & Disclosure

AI usage is **implicitly assumed** and not hidden.

- AI assistance is not denied or obscured
- Explicit disclosure is not required on every artifact
- AI usage is discussed openly if asked, including in interviews

The emphasis is on **quality and ownership**, not provenance signalling.

---

## Skill & Professional Signal

The use of AI is viewed as a professional skill.

The expected signal is:

> “Able to use modern tools to accelerate development and improve code quality, while retaining independent judgement and responsibility.”

The value lies in:
- prompting effectively
- evaluating output critically
- recognising good code versus bad code
- and integrating AI output into coherent systems

---

## Boundaries & Integrity

The following statement reflects RossEngineering practice:

> “AI is used extensively, but nothing ships that is not fully understood and defensible without AI assistance.”

This is a non-negotiable boundary.

---

## Future Guardrail

This policy exists in part to prevent:

- slapdash development
- insecure implementations
- unexamined copy-paste code
- architectural incoherence justified by speed

If AI usage begins to undermine clarity or correctness, practices must change.

---

## Tone & Intent

This policy is intended as **guiding principles and personal practice**, not rigid rules.

It should:
- enable thoughtful use of AI
- protect long-term code quality
- support honest professional discussion
- evolve as tools and practices evolve

---

## Summary

AI is a tool.

Understanding, responsibility, and judgement remain human obligations.

RossEngineering values engineers who use all available tools — **without surrendering ownership of their work**.
